## web常见面试题



------



### 1. 前端需要注意的SEO


1. **合理的title、description、keywords : 搜索引擎对这三项的权重逐个减小，title 值强调重点即可**，重要关键词不要出现超过2次，而且要靠前，不同页面的 title 要有所不同；description 把页面的内容高度概括，长度合适，不可过分堆砌关键词，不同页面的 description 有所不同；keywords 列举出重要关键词即可
2. **语义化的Html代码，符合W3C规范：语义化代码让搜索引擎更容易理解网页**
   - 使用恰当语义的html标签，class类名等内容，让页面具有良好的结构和含义
   - 正确的标签做正确的事情
   - 页面内容结构化
   - 无CSS样子时也容易阅读，便于阅读维护和理解
   - 便于浏览器、搜索引擎解析。利于爬虫标记、利于SEO
3. **重要内容HTML代码放在最前：搜索引擎抓取HTML顺序是从上到下，有的搜索引擎对抓取长度有限制，保证重要内容一定会被抓取**
4. **重要内容不要用js输出：爬虫不会执行js获取内容**
5. **少用iframe：搜索引擎不会抓取iframe中的内容**
6. **非装饰性图片必须加alt**
7.  **提高网站速度：网站速度是搜索引擎排序的一个重要指标**

### 2.  从浏览器地址栏输入 url 到显示页面的步骤

​	**基础版本**

- 浏览器根据请求的`URL`交给`DNS`域名解析，找到真实`IP`，向服务器发起请求；
- 服务器交给后台处理完成后返回数据，浏览器接收文件（`HTML、JS、CSS`、图象等）；
- 浏览器对加载到的资源（`HTML、JS、CSS`等）进行语法解析，建立相应的内部数据结构（如`HTML`的`DOM`）；
- 载入解析到的资源文件，渲染页面，完成。

**详细版**

1. 在浏览器地址栏输入`URL`
2. 浏览器查看*缓存**，如果请求资源在缓存中并且新鲜，跳转到转码步骤
   1. 如果资源未缓存，发起新请求；
   2. 如果已缓存，检验是否足够新鲜，足够新鲜直接提供给客户端，否则与服务器进行验证；
   3. 检验新鲜通常有两个`HTTP`头进行控制`Expires`和`Cache-Control`：
      - HTTP1.0 提供`Expires`，值为一个绝对时间表示缓存新鲜日期
      - HTTP1.1 增加了`Cache-Control:max-age=`，值为以秒为单位的最大新鲜时间
3. 浏览器**解析`URL`**获取协议，主机、端口、path
4. 浏览器组装一个`HTTP（GET）`请求报文
5. 浏览器获取主机`IP`地址，过程如下：
   1. 浏览器缓存
   2. 本机缓存
   3. hosts文件
   4. 路由器缓存
   5. ISP DNS 缓存
   6. DNS 递归查询（可能存在负载均衡导致每次IP不一样）
6. 打开一个`socket`与目标`IP`地址，端口建立`TCP`链接，三次握手如下：
   1. 客户端发送一个TCP的`SYN=1,Seq=X` 的包到服务器端口
   2. 服务器发回`SYN=1,ACK=X+1,Seq=Y` 的响应包
   3. 客户端发送 `ACK=Y+1,Seq=Z`
7. `TCP`链接建立后发送`HTTP`请求
8. 服务器接受请求并解析，将请求转发到服务程序，如虚拟主机使用`HTTP Host` 头部判断请求的服务器程序
9. 服务器检查HTTP请求头是否包含缓存验证信息，如果验证缓存新鲜，返回304等对应状态码
10. 处理程序读取完整请求并准备HTTP响应，可能需要查询数据库等操作
11. 服务器将响应报文通过`TCP`连接发送回浏览器
12. 浏览器接收HTTP响应，然后根据情况选择关闭TCP连接或者保留重用，关闭TCP连接的四次握手如下：
    1. 主动方发送`Fin=1,Ack=Z,Seq=X`报文
    2. 被动方发送`Ack=X+1,Seq=Z`报文
    3. 被动方发送`Fin=1,Ack=X,Seq=Y`报文
    4. 主动方发送`Ack=Y,Seq=X`报文
13. 浏览器检查响应状态码：是否为 1xx，3xx，4xx，5xx，这些情况处理与2xx不同
14. 如果资源可缓存，进行缓存
15. 对响应进行解码（比如gzip压缩）
16. 根据资源类型决定如何处理（假设资源为HTML文档）
17. 解析HTML文档，构建DOM树，下载资源，构造CSSOM树，执行js脚本，这些操作没有严格的先后顺序，以下分别解释：
18. 构建DOM树：
    1. Tokenizing：根据HTML规范将字符流解析为标记
    2. Lexing：词法分析将标记转换为对象并定义属性和规则
    3. DOM construction：根据HTML标记关系将对象组成DOM树
19. 解析过程中遇到图片、样式表、js文件，启动下载
20. 构建CSSOM树
    1. Tokenizing：字符流转换为标记流
    2. Node：根据标记创建节点
    3. CSSOM：节点创建CSSOM树
21. 根据DOM树和CSSOM树构建渲染树
    1. 从DOM树的根节点遍历所有可见节点，不可见节点包括：
       1)`script`,`meta`这样本身不可见的标签。2)被`css`隐藏的节点，如`display: none`
    2. 对每一个可见节点，找到恰当的CSSOM规则并应用
    3. 发布可视节点的内容和计算样式
22. js解析
    1. 浏览器创建`Document`对象并解析`HTML`，将解析到的元素和文本节点添加到文档中，此时`document.readystate`为`loading`
    2. HTML解析器遇到没有`async`和`defer`的`script`时，将他们添加到文档中，然后执行行内或外部脚本。这些脚本会同步执行，并且在脚本下载和执行时解析器会暂停。这样就可以用document.write()把文本插入到输入流中。同步脚本经常简单定义函数和注册事件处理程序，他们可以遍历和操作script和他们之前的文档内容
    3. 当解析器遇到设置了`async`属性的`script`时，开始下载脚本并继续解析文档。脚本会在它下载完成后尽快执行，但是解析器不会停下来等它下载。异步脚本禁止使用document.write()，它们可以访问自己script和之前的文档元素
    4. 当文档完成解析，`document.readState`变成`interactive`
    5. 所有`defer`脚本会按照在文档出现的顺序执行，延迟脚本能访问完整文档树，禁止使用`document.write()`
    6. 浏览器在Document对象上触发DOMContentLoaded事件
    7. 此时文档完全解析完成，浏览器可能还在等待如图片等内容加载，等这些内容完成载入并且所有异步脚本完成载入和执行，`document.readState`变为`complete`，`window`触发`load`事件
23. 显示页面（HTML解析过程中会逐步显示页面）

**详细简版**

1. 从浏览器接收`url`到开启网络请求线程（这一部分可以展开浏览器的机制以及进程与线程之间的关系）
2. 开启网络线程到发出一个完整的`HTTP`请求（这一部分涉及到`dns`查询，`TCP/IP`请求，五层因特网协议栈等知识）
3. 从服务器接收到请求到对应后台接收到请求（这一部分可能涉及到负载均衡，安全拦截以及后台内部的处理等等）
4. 后台和前台的`HTTP`交互（这一部分包括`HTTP`头部、响应码、报文结构、`cookie`等知识，可以提下静态资源的`cookie`优化，以及编码解码，如`gzip`压缩等）
5. 单独拎出来的缓存问题，`HTTP`的缓存（这部分包括`http`缓存头部，`ETag`，`catch-control`等）
6. 浏览器接收到`HTTP`数据包后的解析流程（解析`html`-词法分析然后解析成`dom`树、解析`css`生成`css`规则树、合并成`render`树，然后`layout`、`painting`渲染、复合图层的合成、`GPU`绘制、外链资源的处理、`loaded`和`DOMContentLoaded`等）
7. `CSS`的可视化格式模型（元素的渲染规则，如包含块，控制框，`BFC`，`IFC`等概念）
8. `JS`引擎解析过程（`JS`的解释阶段，预处理阶段，执行阶段生成执行上下文，`VO`，作用域链、回收机制等等）
9. 其它（可以拓展不同的知识模块，如跨域，web安全，`hybrid`模式等等内容）

### 3. 如何进行网站性能优化?

1. content  方面

   - 减少 HTTP 请求：合并文件、css 精灵、inline Image
   - 减少 DNS 查询： DNS 缓存，将资源分布到恰当数量的主机名（CDN）
   - 减少 DOM 元素的数量

2.  Server 方面

   - 使用 CDN

   - 添加 Expires 或者 Cache-Control 响应头

   - 对组件使用 Gzip 压缩

   - 配置 ETag 实体标签   **web服务器用于确认缓存组件的有效性的一种机制**

   - Ajax使用GET进行请求

     ​		备注：浏览器下载组件的时候，会将它们存储到浏览器缓存中。如果需要再次获取相同的组件，浏览器将检查组件的缓存时间，假如已经过期，那么浏览器将发送一个条件 GET 请求到服务器，服务器判断缓存还有效，则发送一个304响应，告诉浏览器可以重用缓存组件。

3. Cookie 方面

   - 减小`cookie `大小
   - 引入资源的域名不要包含 `cookie`

4.  CSS 方面

   - 将样式表放到页面顶部
   - 不使用 CSS 表达式
   - 使用 link 标签 不使用@import

5.  Javascript 方面

   - 将脚本放到页面底部
   - 将 javascript 和css 从外部引入
   - 压缩 javascript 和 css
   - 删除不需要的脚本
   - 减少 DOM 访问
   - 合理设计事件监听器

6.  图片方面

   - 优化图片：根据实际颜色需要选择色深、压缩
   - 优化`css`精灵
   - 不要在HTML中拉伸图片
   - 保证favicon.ico小并且可缓存

### 4. 对浏览器内核的理解

- 主要分成两部分：渲染引擎(`layout engineer`或`Rendering Engine`)和`JS`引擎
- 渲染引擎：负责取得网页的内容（`HTML`、`XML`、图像等等）、整理讯息（例如加入`CSS`等），以及计算网页的显示方式，然后会输出至显示器或打印机。浏览器的内核的不同对于网页的语法解释会有不同，所以渲染的效果也不相同。所有网页浏览器、电子邮件客户端以及其它需要编辑、显示网络内容的应用程序都需要内核
- `JS`引擎：解析和执行`javascript`来实现网页的动态效果，以及交互内容

**常见的浏览器内核有哪些**

- `Trident`内核：`IE,MaxThon,TT,The World,360`,搜狗浏览器等。[又称MSHTML]
- `Gecko`内核：`Netscape6`及以上版本，`FF,MozillaSuite/SeaMonkey`等
- `Presto`内核：`Opera7`及以上。      [`Opera`内核原为：Presto，现为：`Blink`;]
- `Webkit`内核：`Safari,Chrome`等。   [ `Chrome`的`Blink`（`WebKit`的分支）]

### 5.   请描述一下 `cookies`，`sessionStorage` 和 `localStorage` 的区别？

- `cookie`是网站为了标示用户身份而储存在用户本地终端（Client Side）上的数据（通常经过加密）
- cookie 数据始终在同源的 http 请求中携带（即使不需要），记会在浏览器和服务器间来回传递
- `sessionStorage`和`localStorage`不会自动把数据发给服务器，仅在本地保存
- 存储大小：
  - `cookie`数据大小不能超过4k
  - `sessionStorage`和`localStorage`虽然也有存储大小的限制，但比`cookie`大得多，可以达到5M或更大
- 有期时间：
  - `localStorage` 存储持久数据，浏览器关闭后数据不丢失除非主动删除数据
  - `sessionStorage` 数据在当前浏览器窗口关闭后自动删除
  - `cookie` 设置的`cookie`过期时间之前一直有效，即使窗口或浏览器关闭

### 6.  Web 标准以及W3C标准是什么？

- 标签闭合、标签小写、不乱嵌套、使用外链`css`和`js`、结构行为表现的分离

### 7. 为什么利用多个域名来存储网站资源会更有效？

- `CDN`缓存更方便
- 突破浏览器并发限制
- 节约`cookie`带宽
- 节约主域名的连接数，优化页面响应速度
- 防止不必要的安全问题

### 8. 在css/js代码上线之后开发人员经常会优化性能，从用户刷新网页开始，一次js请求一般情况下有哪些地方会有缓存处理？

> `dns`缓存，`cdn`缓存，浏览器缓存，服务器缓存

### 9. 一个页面上有大量的图片（大型电商网站），加载很慢，你有哪些方法优化这些图片的加载，给用户更好的体验。

- 图片懒加载，在页面上的未可视区域可以添加一个滚动事件，判断图片位置与浏览器顶端的距离与页面的距离，如果前者小于后者，优先加载。
- 如果为幻灯片、相册等，可以使用图片预加载技术，将当前展示图片的前一张和后一张优先下载。
- 如果图片为css图片，可以使用`CSSsprite`，`SVGsprite`，`Iconfont`、`Base64`等技术。
- 如果图片过大，可以使用特殊编码的图片，加载时会先加载一张压缩的特别厉害的缩略图，以提高用户体验。
- 如果图片展示区域小于图片的真实大小，则因在服务器端根据业务需要先行进行图片压缩，图片压缩后大小与展示一致。

### 10. web开发中会话跟踪的方法有哪些

- `cookie`
- `session`
- `url`重写
- 隐藏`input`
- `ip`地址

### 11. 请你谈谈Cookie的弊端

> `cookie`虽然在持久保存客户端数据提供了方便，分担了服务器存储的负担，但还是有很多局限性的

- 每个特定的域名下最多生成`20`个`cookie`
- `IE6`或更低版本最多`20`个`cookie`
- `IE7`和之后的版本最后可以有`50`个`cookie`
- `Firefox`最多50个`cookie`
- `chrome`和`Safari`没有做硬性限制
- IE 和 Opera 会清理近期最少使用的 `cookie`，`Firefox` 会随机清理 `cookie`
- `cookie` 的最大大约为 `4096` 字节，为了兼容性，一般设置不超过 `4095` 字节
- 如果 `cookie` 被人拦截了，就可以取得所有的 `session` 信息

### 12. 浏览器缓存

> 浏览器缓存分为强缓存和协商缓存。当客户端请求某个资源时，获取缓存的流程如下

- 先根据这个资源的一些 `http header` 判断它是否命中强缓存，如果命中，则直接从本地获取缓存资源，不会发请求到服务器；
- 当强缓存没有命中时，客户端会发送请求到服务器，服务器通过另一些`request header`验证这个资源是否命中协商缓存，称为`http`再验证，如果命中，服务器将请求返回，但不返回资源，而是告诉客户端直接从缓存中获取，客户端收到返回后就会从缓存中获取资源；
- 强缓存和协商缓存共同之处在于，如果命中缓存，服务器都不会返回资源； 区别是，强缓存不对发送请求到服务器，但协商缓存会。
- 当协商缓存也没命中时，服务器就会将资源发送回客户端。
- 当 `ctrl+f5` 强制刷新网页时，直接从服务器加载，跳过强缓存和协商缓存；
- 当 `f5`刷新网页时，跳过强缓存，但是会检查协商缓存；

### 13 WebSocket

> 由于 `http` 存在一个明显的弊端（消息只能有客户端推送到服务器端，而服务器端不能主动推送到客户端），导致如果服务器如果有连续的变化，这时只能使用轮询，而轮询效率过低，并不适合。于是 `WebSocket`被发明出来

> 相比与 `http` 具有以下有点

- 支持双向通信，实时性更强；
- 可以发送文本，也可以二进制文件；
- 协议标识符是 `ws`，加密后是 `wss` ；
- 较少的控制开销。连接创建后，`ws`客户端、服务端进行数据交换时，协议控制的数据包头部较小。在不包含头部的情况下，服务端到客户端的包头只有`2~10`字节（取决于数据包长度），客户端到服务端的的话，需要加上额外的4字节的掩码。而`HTTP`协议每次通信都需要携带完整的头部；
- 支持扩展。ws协议定义了扩展，用户可以扩展协议，或者实现自定义的子协议。（比如支持自定义压缩算法等）
- 无跨域问题。

> 实现比较简单，服务端库如 `socket.io`、`ws`，可以很好的帮助我们入门。而客户端也只需要参照 `api` 实现即可

### 14 尽可能多的说出你对 Electron 的理解

> 最最重要的一点，`electron` 实际上是一个套了 `Chrome` 的 `nodeJS`程序

**所以应该是从两个方面说开来**

- `Chrome` （无各种兼容性问题）；
- `NodeJS`（`NodeJS` 能做的它也能做）

### 15 WEB应用从服务器主动推送Data到客户端有那些方式

- `AJAX` 轮询
- `html5` 服务器推送事件 `(new EventSource(SERVER_URL)).addEventListener("message", func);`
- `html5 Websocket`

- `(new WebSocket(SERVER_URL)).addEventListener("message", func);`